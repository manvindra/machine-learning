{
  "cells": [
    {
      "metadata": {
        "_uuid": "9c05cb33d085d3159b06546b1fde005ae96603b1",
        "_cell_guid": "6d047d0e-7e99-42c0-b95a-a21e544fe717",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6bff3fdf910535eb3a3c015a8d8aacf34425c51a",
        "_cell_guid": "a28d0a8b-2b4a-49ca-bb16-f27ad8cb223a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b20490660a7553e4095d5f54d0a36bd0fecbfd12",
        "_cell_guid": "db295069-3315-4869-b551-09005365b8ac",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_json('../input/train.json')\ntest = pd.read_json(\"../input/test.json\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "160753e86f29790b98ac66f0bb02693c03b43737",
        "_cell_guid": "f1387f4a-06c3-43af-b46d-a98cd8f1efa4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#inc_angle to Numeric from float\ntrain['inc_angle'] = pd.to_numeric(train['inc_angle'],errors='coerce')\ntest['inc_angle'] = pd.to_numeric(test['inc_angle'],errors='coerce')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "60c1ab4a1ebce322eb0c3ac32caa3bc963f4f4fd",
        "_cell_guid": "fd38f094-c0b8-424d-803e-8089d2c071da",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "f,ax = plt.subplots(1,1,figsize=(15,6))\nsns.barplot(x=['not an iceberg','iceberg'],y=train.groupby(['is_iceberg'],as_index=False).count()['id'])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b0b3a4ff758527d95e3e685171861d01f3bd219f",
        "_cell_guid": "37ec0737-7508-43e8-8c6f-ede149332fc1",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train['inc_angle'].describe() # NA exsists",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0da78244bf99925a893db4d3ea6cf9311ee24327",
        "_cell_guid": "ea007ee2-0da0-4b86-90a7-df2e4b2d5f5b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "icebergs = train[train.is_iceberg==1].sample(n=9,random_state=123)\nships = train[train.is_iceberg==0].sample(n=9,random_state=456)\n#Plotting Images:Iceberg\nfig = plt.figure(1,figsize=(15,15))\nfor i in range(9):\n    ax = fig.add_subplot(3,3,i+1)\n    arr = np.reshape(np.array(icebergs.iloc[i,0]),(75,75))\n    ax.imshow(arr)\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5377135485741cc4b409187e3ff3c83e476c38e2",
        "_cell_guid": "4eb8b3ff-b976-480a-85c8-5e1b392aa80b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Plotting Images:Iceberg Band 2\nfig = plt.figure(1,figsize=(15,15))\nfor i in range(9):\n    ax = fig.add_subplot(3,3,i+1)\n    arr = np.reshape(np.array(icebergs.iloc[i,1]),(75,75))\n    ax.imshow(arr)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "59ffd48495cc0bbe69ee025b6557cb607e0d28cb",
        "_cell_guid": "a54928a8-73be-42b2-bb8e-3dc520b175ae",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_scaled_imgs(df):\n    imgs = []\n    \n    for i, row in df.iterrows():\n        #make 75x75 image\n        band_1 = np.array(row['band_1']).reshape(75, 75)\n        band_2 = np.array(row['band_2']).reshape(75, 75)\n        band_3 = band_1 + band_2 \n        \n        # Rescale\n        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n\n        imgs.append(np.dstack((a, b, c)))\n\n    return np.array(imgs)    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad29dc83f5dc742a0c2ae9311eef2f54020c8af2",
        "_cell_guid": "35e5bb17-bd52-455a-88d2-6e7fc0075c6f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Image with 3 Bands\nXtrain = get_scaled_imgs(train)\nYtrain = np.array(train['is_iceberg'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc87b79c1c22dfce34e04122138bdaa62bd1597a",
        "_cell_guid": "bafe8987-065b-456c-9326-5846f4c2206d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import cv2\ndef transform_image(image,ang_range,shear_range,trans_range):\n# Rotation\n    ang_rot = np.random.uniform(ang_range)-ang_range/2\n    rows,cols,ch = image.shape    \n    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n# Translation\n    tr_x = trans_range*np.random.uniform()-trans_range/2\n    tr_y = trans_range*np.random.uniform()-trans_range/2\n    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n    image = cv2.warpAffine(image,Rot_M,(cols,rows))\n    image = cv2.warpAffine(image,Trans_M,(cols,rows))\n    \n    \n    return image",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ffb63fca556157154b9d3a46f14cff03539cc8b2",
        "_cell_guid": "4d4326e0-bf73-4a0e-999c-373ca2a6081a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Augmentation Translation + Rotation\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8d0153e933d6052016a89f46cca2198b781fe85a",
        "_cell_guid": "0849147e-5d83-4790-8087-70780e8b2fca",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Flip Images\ndef get_more_images(imgs):\n    more_images = []\n    aug_imgs = []\n    vert_flip_imgs = []\n    hori_flip_imgs = []\n      \n    for i in range(0,imgs.shape[0]):\n        a=imgs[i,:,:,0]\n        b=imgs[i,:,:,1]\n        c=imgs[i,:,:,2]\n        \n        av=cv2.flip(a,1)\n        ah=cv2.flip(a,0)\n        bv=cv2.flip(b,1)\n        bh=cv2.flip(b,0)\n        cv=cv2.flip(c,1)\n        ch=cv2.flip(c,0)\n        \n        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n      \n    v= np.array(vert_flip_imgs)\n    h = np.array(hori_flip_imgs)\n    \n    for j in range(2):\n        for i in range(0,imgs.shape[0]):\n            aug_imgs.append(transform_image(imgs[i],10,10,2))\n    \n    aug_image=np.array(aug_imgs)\n       \n    more_images = np.concatenate((imgs,v,h,aug_image))\n    \n    return more_images",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5f286ae1b3dfc478a80a73ef2c754b57c6a7e7ca",
        "_cell_guid": "dfa2a80f-116c-427e-88b4-cc2a86212383",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(Xtrain, Ytrain, test_size=0.25)\n\nXtr_more = get_more_images(X_train) \nYtr_more = np.concatenate((y_train,y_train,y_train,y_train,y_train))\nX_valid_more = get_more_images(X_valid)\ny_valid_more = np.concatenate([y_valid,y_valid,y_valid,y_valid,y_valid])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8596cefe9f60577329a26bab7ab52b9690111d0b",
        "_cell_guid": "87c27150-5be1-4e36-83e8-0d14b33c14fd",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "Xtr_more.shape,Ytr_more.shape,X_valid_more.shape,y_valid_more.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fca1828ad4ec4ed9ec6003033416fbb97c0a3bdb",
        "_cell_guid": "5404cf76-ee31-4437-b483-68075acfd0a4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Import Keras.\nfrom matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "109768facdfa2ef5c85ab72ee77e496f63c6a66d",
        "_cell_guid": "04b6b2bc-96d0-4cbf-b064-0350787d0a03",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def getModel():\n    #Building the model\n    model=Sequential()\n    #Conv Layer 1\n    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same', input_shape=(75, 75, 3)))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.2))\n\n    #Conv Layer 2\n    model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu' ))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    #Conv Layer 3\n    model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    #Conv Layer 4\n    model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.2))\n\n#     #Flatten the data for upcoming dense layers\n#     model.add(Flatten())\n\n    #Dense Layers\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.2))\n\n    #Dense Layer 2\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.2))\n\n    #sigmoid Layer\n    model.add(Dense(1, activation='sigmoid'))\n\n    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n#     mypotim = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss='binary_crossentropy',optimizer=mypotim,metrics=['accuracy'])\n    model.summary()\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3c646f8912e99f76a1e00b5f5b20d53db85341f4",
        "_cell_guid": "eb881cea-b8d8-4181-b800-b6d09fb0eeb7",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_stack1_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6dd6bffe24a5ca33471dbbf569da97a9f27b03c9",
        "_cell_guid": "d5f03851-6366-4a71-889f-8350ac8945d8",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nmodel=getModel()\nmodel.fit(Xtr_more, Ytr_more,\n          batch_size=24,\n          epochs=20,\n          verbose=1,\n          validation_data=(X_valid_more, y_valid_more),\n          callbacks=callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f3dfb2bd907d30965755f66ddcac9a397d82f1f4",
        "_cell_guid": "741203ca-873b-4104-9be1-d80289ab3212",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.load_weights(filepath=file_path)\nscore = model.evaluate(X_valid_more, y_valid_more, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\n# 1604/1604 [==============================] - 10s 6ms/step\n# Test loss: 0.166926259783\n# Test accuracy: 0.937032418953",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "99d42b32aac3709bfce9d313c21a27c67d17f558",
        "_cell_guid": "34a701e6-3e55-4e10-a096-a1f3ef726d06",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Submission\nXtest = get_scaled_imgs(test)\npredicted_test=model.predict_proba(Xtest)\nsubmission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('submission_Stack1.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c4e95247e39bfdbb2218fd04c3875e3c761ee41c",
        "_cell_guid": "2f90219e-72fd-492b-983f-f3527324625b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Model 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "00acc04c96f5d73ffd69610d6a488516036b4771",
        "_cell_guid": "edd6b233-2ac4-4455-9bd4-6a2387be4cc4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_model2():\n    \n    \"\"\"\n    Keras Sequential model\n\n    \"\"\"\n    \n    model=Sequential()\n    \n    # Conv block 1\n    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same', input_shape=(75, 75, 3)))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n   \n    # Conv block 2\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same', ))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n   \n    # Conv block 3\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same',))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    \n    #Conv block 4\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same',))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.2))\n\n    #Dense 1\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.4))\n\n    #Dense 2\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.2))\n\n    # Output \n    model.add(Dense(1, activation=\"sigmoid\"))\n\n    \n    model.compile(loss='binary_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f83141a2aaa07dcf5f2ab77826928f9072b39abf",
        "_cell_guid": "90fe7da4-5cc7-433b-a3a0-41e98f6576ae",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold\nseed = 1234\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\nfor fold_n, (train, test) in enumerate(kfold.split(Xtr_more, Ytr_more)):\n    print(\"FOLD nr: \", fold_n)\n    model2 = get_model2()\n    \n    MODEL_FILE = 'mdl_simple_k{}_wght.hdf5'.format(fold_n)\n    batch_size = 32\n    mcp_save = ModelCheckpoint(MODEL_FILE, save_best_only=True, monitor='val_loss', mode='min')\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, epsilon=1e-4, mode='min')\n\n    # set the epochs to 30 before training on your GPU\n    model2.fit(Xtr_more[train], Ytr_more[train],\n        batch_size=batch_size,\n        epochs=15,\n        verbose=1,\n        validation_data=(Xtr_more[test], Ytr_more[test]),\n        callbacks=[mcp_save, reduce_lr_loss])\n    \n    model2.load_weights(filepath = MODEL_FILE)\n    \n    score = model2.evaluate(Xtr_more[test], Ytr_more[test], verbose=1)\n    print('\\n Val score:', score[0])\n    print('\\n Val accuracy:', score[1])\n    \n    SUBMISSION = 'sub_STACK_Model2_{}.csv'.format(fold_n)\n    \n    df_test = pd.read_json('../input/test.json')\n    df_test.inc_angle = df_test.inc_angle.replace('na',0)\n    Xtest = (get_scaled_imgs(df_test))\n    pred_test = model2.predict(Xtest)\n\n    submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': pred_test.reshape((pred_test.shape[0]))})\n    print(submission.head(10))\n\n    submission.to_csv(SUBMISSION, index=False)\n    print(\"submission saved\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f98abd5cb2b5fe224b18de73796708b727f337b8",
        "_cell_guid": "21c4bda4-9242-45a5-9980-8b9377556a1d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"done\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fee4cfdc2276c42fa7b1c3ef1460a3413002eddd",
        "_cell_guid": "f00488df-e722-4efe-9fbf-dfe29b090c3c",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# #load Submission File\n# sub_path = \"../input/statoil-iceberg-submissions\"\n# all_files = os.listdir(sub_path)\n\n# # Read and concatenate submissions\n# outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n# concat_sub = pd.concat(outs, axis=1)\n# cols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_sub.columns))))\n# concat_sub.columns = cols\n# concat_sub.reset_index(inplace=True)\n# concat_sub.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4e5fa7b5a2bea8db1631891395b60d50e72b568c",
        "_cell_guid": "58fbfdbb-87d3-45bd-832f-e4b2c0ccd77d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# # check correlation\n# concat_sub.corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "503a31debce533e7eb6f0caedb5f75fbe399c963",
        "_cell_guid": "5ad18149-9d42-4ef3-92b1-05da501d7d7a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# #MinMax + Median Stacking\n# concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n#                                     concat_sub['is_iceberg_max'], \n#                                     np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n#                                              concat_sub['is_iceberg_min'], \n#                                              concat_sub['is_iceberg_median']))\n# concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_median.csv', \n#                                         index=False, float_format='%.6f')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}